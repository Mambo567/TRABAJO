{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi칩n lineal simple y polin칩mica\n",
    "#### Regresi칩n lineal simple:\n",
    "- Definici칩n: Modela la relaci칩n lineal entre una variable independiente 洧녦 y una dependiente 洧녧.\n",
    "- Uso: Predecir valores continuos, como precio de una casa basado en tama침o.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "#### Regresi칩n polin칩mica:\n",
    "- Definici칩n: Extensi칩n de la regresi칩n lineal, pero modela relaciones no lineales elevando 洧녦 a potencias (grados polinomiales).\n",
    "- Uso: Predecir relaciones curvas, como la trayectoria de un objeto lanzado.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "### Regresi칩n log칤stica\n",
    "- Definici칩n: Aunque se llama \"regresi칩n\", es un modelo de clasificaci칩n que calcula probabilidades para asignar etiquetas binarias (0/1).\n",
    "- Uso: Clasificaci칩n binaria, como determinar si un correo es spam o no.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "### DecisionTreeClassifier y DecisionTreeRegressor\n",
    "#### DecisionTreeClassifier:\n",
    "- Definici칩n: Divide datos en ramas bas치ndose en valores de caracter칤sticas, creando una estructura tipo 치rbol para clasificar.\n",
    "- Uso: Clasificaci칩n multiclase o binaria, como predecir si un cliente comprar치 un producto.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### DecisionTreeRegressor:\n",
    "- Definici칩n: Igual que el anterior, pero predice valores continuos en lugar de etiquetas.\n",
    "- Uso: Estimar ingresos anuales seg칰n educaci칩n y experiencia.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "### RandomForestClassifier y RandomForestRegressor\n",
    "#### RandomForestClassifier\n",
    "- Definici칩n: Ensamble de muchos 치rboles de decisi칩n entrenados en subconjuntos aleatorios de los datos y caracter칤sticas. La predicci칩n es por votaci칩n mayoritaria.\n",
    "- Uso: Clasificaci칩n robusta con datos con ruido, como diagn칩stico m칠dico.\n",
    "- Problema: Clasificaci칩n.\n",
    "- **쯈u칠 hiperpar치metros deber칤a tocar en el RandomForest?**\n",
    "    1. `n_estimators`: n칰mero de 치rboles que participar치n en las votaciones. Cuantos m치s mejor. NO producen overfitting. Cuanto m치s complejo es el dataset, mejor vendr치 que haya muchos 치rboles. M치s de 200 suele ser redundante.\n",
    "    2. `max_depth`: profundida de los 치rboles. Cuanto m치s profundos, m치s complejo es el modelo, pero menos generaliza. De  nuevo, cuanto m치s complejo es el problema, mayor profundidad necesitaremos. No m치s de 20/30 es lo normal.\n",
    "    3. `max_features`: features a tener en cuenta en los splits del 치rbol. Cuanto m치s bajo, mejor generalizar치 y menos overfitting. Numero menor a la cantidad de features del dataset, sino dar치 error.\n",
    "    4. `min_samples_split`: m칤nima cantidad de muestras en un nodo antes de ser spliteado. 2 por defecto. N칰meros bajos suelen dar buenos resultados (<50). Cuanto m치s alto, mejor generaliza, pero m치s baja la precisi칩n.\n",
    "    5. `min_samples_leaf`: m칤nima cantidad de puntos permitidos en un `leaf node`, es decir, un nodo que no va a volver a ser spliteado. Valores bajos funcionan bien (<50).\n",
    "\n",
    "#### RandomForestRegressor\n",
    "- Funciona igual pero predice valores continuos.\n",
    "\n",
    "### VotingClassifier y VotingRegressor\n",
    "#### VotingClassifier\n",
    "- Definici칩n: Combina predicciones de diferentes modelos (pueden ser variados, como SVM, 치rboles, etc.), eligiendo la clase por votaci칩n (mayor칤a o promedio).\n",
    "- Uso: Meta-modelo para mejorar la robustez.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### VotingRegressor\n",
    "- Definici칩n: Un meta-modelo que combina predicciones de varios modelos base regresores. Las predicciones finales son una media ponderada (o no ponderada) de las salidas de los modelos base.\n",
    "- Uso: cuando se quieren combinar m칰ltiples modelos regresores para obtener una predicci칩n robusta. Por ejemplo:\n",
    "- Predicci칩n de precios de vivienda utilizando un ensamble de un modelo lineal, un Random Forest y un Gradient Boosting.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "### BaggingClassifier y BaggingRegressor\n",
    "#### BaggingClassifier\n",
    "- Sistema de clasificaci칩n por votaci칩n de algoritmos. En este caso siempre es el mismo tipo de algoritmo, habitualmente 치rboles de decisi칩n.\n",
    "- Definici칩n: T칠cnica de ensamble que entrena m칰ltiples modelos base (por ejemplo, 치rboles) en subconjuntos aleatorios de los datos con reemplazo (bootstrap) y combina sus resultados.\n",
    "- Uso: Reducir la varianza y mejorar la generalizaci칩n.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### BaggingRegressor\n",
    "- Definici칩n: T칠cnica de ensamble que entrena m칰ltiples versiones de un modelo base regresor en subconjuntos aleatorios (con reemplazo) de los datos de entrenamiento y promedia sus predicciones.\n",
    "- Uso: para reducir la varianza de modelos inestables como los 치rboles de decisi칩n. Por ejemplo:\n",
    "- Predicci칩n de temperaturas diarias bas치ndose en datos hist칩ricos.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "### AdaBoostClassifier y AdaBoostRegressor\n",
    "#### AdaBoostClassifier\n",
    "- Definici칩n: Ensamble de boosting que da m치s peso a las instancias mal clasificadas en iteraciones sucesivas, ajustando modelos base (como 치rboles).\n",
    "- Uso: Clasificaci칩n en datos desequilibrados o complejos.\n",
    "- Problema: Clasificaci칩n.\n",
    "- **쯈u칠 hiperpar치metros deber칤a tocar en el AdaBoostClassifier?**\n",
    "    1. `n_estimators`: n칰mero de 치rboles que participar치n en la correcci칩n secuencial del error del modelo. Si corregimos el error a la perfecci칩n el algoritmo termina de entrenar. Cuantos m치s estimadores, mejor corregiremos el error pero mayor probabilidad de caer en overfitting. Valores superiores a 100 suelen sobreajustar el modelo aunque depender치 de la complejidad y volumen de los datos.\n",
    "    2. `learning_rate`: no suele tener valores superiores a 1. Cuanto m치s alto, m치s aporta cada nuevo 치rbol, m치s preciso, pero caemos en overfitting. **Importante**: un learning rate bajo y alto n칰mero de estimadores no necesariamente tiene por qu칠 aumentar la precisi칩n y si va a inducir en altos costes computacionales.\n",
    "    3. `algorithm`: 'SAME' o 'SAME.R'. 'SAME.R' utiliza la probabilidad para actualizar los modelos aditivos, mientras que 'SAME' usa los valores de clasificaci칩n. Similar a soft vs hard voting. 'SAMME.R' converge antes que 'SAMME'\n",
    "    4. `base_estimator`: se suele dejar por defecto, aunque podr칤a encajar un SVM o una Regresi칩nLog칤stica\n",
    "    5. `max_depth`: **OJO**, no es un hiperpar치metro del AdaBoostClassifier, sino del DecisionTreeClassifier. Habr치 que probar varios 치rboles con diferentes `max_depth` y despu칠s ponerlos como `base_estimator` en el AdaBoost. Cuanto mayor es este hiperpar치metro, m치s preciso, pero tambi칠n m치s overfitting.\n",
    "\n",
    "#### AdaBoostRegressor\n",
    "Definici칩n: Igual que AdaBoostClassifier, pero para predicci칩n continua.\n",
    "Uso: Estimar valores como temperaturas futuras.\n",
    "Problema: Regresi칩n.\n",
    "\n",
    "### ExtraTreesClassifier y ExtraTreesRegressor\n",
    "#### ExtraTreesClassifier\n",
    "- Definici칩n: Similar a Random Forest, pero introduce m치s aleatoriedad al elegir los puntos de divisi칩n en los 치rboles, lo que reduce la varianza pero puede aumentar el sesgo.\n",
    "- Uso: Clasificaci칩n en datos con muchas caracter칤sticas redundantes.\n",
    "- Problema: Clasificaci칩n.\n",
    "- Nota clave: Es 칰til cuando el dataset es grande y hay correlaciones significativas entre caracter칤sticas. Su ventaja sobre Random Forest es que es m치s r치pido, ya que no busca las divisiones 칩ptimas.\n",
    "\n",
    "#### ExtraTreesRegressor\n",
    "- Definici칩n: Modelo similar al RandomForestRegressor, pero con una diferencia clave: en el RFR el modelo busca divisiones 칩ptimas (splits) en los nodos de cada 치rbol, en ExtraTrees las divisiones se eligen de forma completamente aleatoria dentro de un rango de valores de las features seleccionadas. Esto incrementa la aleatoriedad y suele hacer al modelo m치s r치pido y menos propenso al sobreajuste.\n",
    "- Caracter칤sticas principales:\n",
    "    - Aleatoriedad extrema: Los splits en los nodos son completamente aleatorios, no el resultado de optimizaci칩n como en Random Forest.\n",
    "    - Rapidez: Debido a la falta de optimizaci칩n en cada nodo, entrena m치s r치pido que un Random Forest.\n",
    "    - Menor sobreajuste: La aleatoriedad adicional act칰a como una forma de regularizaci칩n, haciendo que generalice mejor en algunos casos.\n",
    "- Cu치ndo usarlo: Cuando necesitas un modelo de regresi칩n basado en 치rboles r치pido y robusto. \n",
    "- En datasets donde hay muchas features redundantes o ruido, ya que la aleatoriedad puede evitar sobreajuste.\n",
    "- Problema: Solo se utiliza en regresi칩n.\n",
    "\n",
    "### GradientBoostingClassifier y GradientBoostingRegressor\n",
    "- El GradientBoosting funciona s칩lo con 치rboles, por eso no es posible cambiar el estimador. \n",
    "- Directamente los hiperpar치metros a configurar en en GradientBoosting son los del DecissionTree.\n",
    "- **쯈u칠 hiperpar치metros deber칤a tocar en el GradientBoosting?**\n",
    "    1. `n_estimators`: n칰mero de 치rboles que participar치n en la correcci칩n secuencial del error del modelo. Si corregimos el error a la perfecci칩n el algoritmo termina de entrenar. Cuantos m치s estimadores, mejor corregiremos el error pero mayor probabilidad de caer en overfitting. Valores superiores a 100 suelen sobreajustar el modelo aunque depender치 de la complejidad y volumen de los datos.\n",
    "    2. `learning_rate`: no suele tener valores superiores a 1. Cuanto m치s alto, m치s aporta cada nuevo 치rbol, m치s preciso, pero caemos en overfitting. **Importante**: un learning rate bajo y alto n칰mero de estimadores no necesariamente tiene por qu칠 aumentar la precisi칩n y si va a inducir en altos costes computacionales.\n",
    "    3. `max_depth`: Cuanto mayor es este hyperpar치metro, m치s preciso, pero tambi칠n m치s overfitting.\n",
    "    - Se puede iterar sobre todos los hiperpar치metros recorridos en el RandomForest\n",
    "#### GradientBoostingClassifier\n",
    "- Definici칩n: Igual que el regressor, pero para clasificaci칩n.\n",
    "- Uso: Diagn칩sticos m칠dicos multiclase.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### GradientBoostingRegressor\n",
    "- Definici칩n: T칠cnica de boosting que ajusta modelos secuenciales para corregir errores residuales, optimizando una m칠trica de p칠rdida espec칤fica.\n",
    "- Uso: Predecir valores como tasas de inter칠s.\n",
    "- Problema: Regresi칩n.\n",
    "- Explicaci칩n clave: Aunque solo usa 치rboles de decisi칩n como estimadores base, permite configurar hiperpar치metros como profundidad m치xima o n칰mero de nodos para personalizar los 치rboles.\n",
    "\n",
    "### CatBoostClassifier y CatBoostRegressor\n",
    "#### CatBoostClassifier:\n",
    "- Definici칩n: Ensamble avanzado de boosting optimizado para datos categ칩ricos, sin necesidad de convertirlos manualmente a variables dummies.\n",
    "- Uso: Clasificaci칩n con muchas caracter칤sticas categ칩ricas, como datos de encuestas.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### CatBoostRegressor:\n",
    "- Definici칩n: Igual que el anterior, pero para regresi칩n.\n",
    "- Uso: Predecir ventas basadas en categor칤as como regi칩n o producto.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "### XGBClassifier y XGBRegressor\n",
    "- **쯈u칠 hiperpar치metros deber칤a tocar en el XGB?**\n",
    "    1. `n_estimators`: igual que para el GradientBoosting.\n",
    "    2. `booster`: tipo de modelo que correr치 en cada iteraci칩n. Arboles o regresiones. `gbtree` or `gblinear`. Los 치rboles suelen ir bien.\n",
    "    3. `learning_rate`: o tambi칠n llamado `eta`. Como el learning rate del GradientBoosting.\n",
    "    4. `max_depth`: nada nuevo\n",
    "    - Si quieres afinar m치s todav칤a el XGBoost consulta [esta completa gu칤a](https://www.analyticsvidhya.com/blog/2016/03 complete-guide-parameter-tuning-xgboost-with-codes-python/).\n",
    "#### XGBClassifier:\n",
    "- Definici칩n: Versi칩n para clasificaci칩n de XGBoost.\n",
    "- Uso: Problemas de clasificaci칩n binaria o multiclase.\n",
    "- Problema: Clasificaci칩n.\n",
    "\n",
    "#### XGBRegressor:\n",
    "- Definici칩n: Implementaci칩n eficiente y r치pida de Gradient Boosting dise침ada por XGBoost para regresi칩n.\n",
    "- Uso: Predicciones como gasto energ칠tico.\n",
    "- Problema: Regresi칩n.\n",
    "\n",
    "## Modelos adicionales importantes\n",
    "\n",
    "#### Support Vector Machines (SVM):\n",
    "- Definici칩n: Encuentra un hiperplano 칩ptimo para clasificar datos. Puede usarse para regresi칩n (SVR) y clasificaci칩n (SVC).\n",
    "- Problema: Ambas.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN):\n",
    "- Definici칩n: Clasifica datos bas치ndose en las clases m치s comunes entre los vecinos m치s cercanos.\n",
    "- Problema: Clasificaci칩n, pero tambi칠n regresi칩n.\n",
    "\n",
    "#### Naive Bayes:\n",
    "- Definici칩n: Modelo probabil칤stico basado en la aplicaci칩n del teorema de Bayes.\n",
    "- Problema: Clasificaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunos insights valiosos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cross-validation con todo el dataset vs. divisi칩n previa en train/test\n",
    "\n",
    "En un flujo de trabajo ideal de Machine Learning:\n",
    "\n",
    "1) Primero divides los datos en train y test para simular un entorno real de evaluaci칩n del modelo. El conjunto test se mantiene separado hasta el final del proceso, para garantizar que las m칠tricas no est칠n sesgadas por decisiones previas.\n",
    "\n",
    "2) En el conjunto de entrenamiento (train), aplicas:\n",
    "\n",
    "3) Cross-validation para entrenar y evaluar iterativamente los modelos.\n",
    "\n",
    "4) Feature engineering y ajustes de hiperpar치metros (si es necesario).\n",
    "\n",
    "En el caso del ejercicio que describes, hacer la cross-validation con todo el dataset (sin dividir en train/test) puede ser 칰til en fases exploratorias cuando:\n",
    "- No necesitas evaluar el modelo de forma estricta en un conjunto independiente.\n",
    "- Quieres entender c칩mo se comportan diferentes modelos en tus datos.\n",
    "\n",
    "Sin embargo, en un proyecto real, esto ser칤a una mala pr치ctica, porque el modelo puede sobreajustarse a los datos al no tener un conjunto de validaci칩n separado.\n",
    "\n",
    "### 2. Ensamble y elecci칩n del mejor modelo\n",
    "\n",
    "El ensamble de modelos no consiste en elegir uno mejor, sino en combinar varios modelos para obtener una predicci칩n m치s robusta y precisa. Aqu칤 hay dos puntos clave:\n",
    "\n",
    "Ensamblar modelos (como en bagging, boosting o stacking): Se usan m칰ltiples modelos en conjunto, y sus predicciones se combinan para obtener una predicci칩n final (por votaci칩n o promediaci칩n, por ejemplo).\n",
    "\n",
    "Si no est치s ensamblando, sino probando diferentes algoritmos, entonces es normal evaluar varios modelos y elegir el que mejor rendimiento tenga.\n",
    "\n",
    "En este caso, el ejercicio te gu칤a para comparar varios algoritmos (Bagging, Random Forest, AdaBoost, Gradient Boosting y XGBoost) con cross-validation en todo el dataset, pero en un proyecto real lo har칤as solo con el conjunto de entrenamiento.\n",
    "\n",
    "### 3. Flujo de trabajo ideal de ML\n",
    "\n",
    "Un flujo t칤pico para proyectos de ML ser칤a:\n",
    "\n",
    "1) Divisi칩n inicial:\n",
    "- Divide los datos en train (80%) y test (20%).\n",
    "2) Feature engineering:\n",
    "- Realiza preprocesamiento, normalizaci칩n, imputaci칩n, etc., solo en train. El profe dice que se deberia hacer cross_val aqui tambien, pero que generalmente no se hace. \n",
    "3) Cross-validation:\n",
    "- Utiliza cross-validation solo en el conjunto de train para entrenar y comparar modelos.\n",
    "- Eval칰a diferentes algoritmos, ajusta hiperpar치metros, y selecciona el modelo o ensamble que mejor generalice.\n",
    "- Se ajustan los hiperparametros con GridSearch (ver despues) para elegir el mejor (o top3) modelo. \n",
    "- El que mejor me de, sera mi modelo. \n",
    "4) Evaluaci칩n final:\n",
    "- Una vez elegido el modelo, lo entrenas con todo el conjunto de train.\n",
    "- Eval칰as su rendimiento en el conjunto de test, que no se toc칩 antes.\n",
    "5) Validaci칩n adicional (opcional):\n",
    "- Usa un conjunto de datos externo o validaci칩n cruzada avanzada si es posible.\n",
    "\n",
    "\n",
    "Respuesta a tu 칰ltima pregunta:\n",
    "\n",
    "El objetivo de los ensamblados no es elegir un modelo 칰nico, sino usar varios modelos combinados para lograr un mejor rendimiento global. Pero en este ejercicio en particular, tambi칠n te est치n pidiendo que compares diferentes t칠cnicas de ensamble (bagging, boosting, etc.).\n",
    "\n",
    "Si quieres hacer este ejercicio correctamente en un proyecto real, ser칤a mejor realizar el train-test split al inicio, trabajar con train para todo lo dem치s (ensamblados y comparaciones), y evaluar el mejor modelo elegido en el conjunto test al final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "\n",
    "- T칠cnica utilizada para encontrar la mejor combinaci칩n de hiperpar치metros para un modelo de machine learning. **Trabaja en conjunto con cross-validation** para evaluar el rendimiento de cada combinaci칩n de hiperpar치metros en los datos de entrenamiento, seleccionando la que maximiza una m칠trica de evaluaci칩n definida (por ejemplo, accuracy, F1-score, RMSE, etc.).\n",
    "\n",
    "- 쮺칩mo funciona GridSearch? \n",
    "    - Definir los hiperpar치metros a ajustar: Por ejemplo, si est치s trabajando con un RandomForestClassifier, podr칤as definir un rango para los hiperpar치metros n_estimators, max_depth, y min_samples_split.\n",
    "    - Crear una malla de combinaciones posibles: GridSearch probar치 todas las combinaciones de los valores especificados para los hiperpar치metros.\n",
    "    - Realizar cross-validation para cada combinaci칩n: Usa el conjunto de datos de entrenamiento, dividi칠ndolo en varios folds, y eval칰a el rendimiento del modelo en cada fold.\n",
    "    - Seleccionar la mejor combinaci칩n: Una vez evaluadas todas las combinaciones, GridSearch devuelve los hiperpar치metros que obtuvieron el mejor rendimiento promedio en los folds.\n",
    "\n",
    "- 쮺u치ndo se usa GridSearch? No siempre es necesario. Solo deber칤as usar GridSearch si el modelo tiene m칰ltiples hiperpar치metros que afectan significativamente su rendimiento, y no tienes una idea clara de cu치les son los mejores valores.\n",
    "    1) Optimizaci칩n de hiperpar치metros: Si el modelo que est치s entrenando tiene hiperpar치metros que impactan significativamente su rendimiento (por ejemplo, la profundidad de un 치rbol en un DecisionTreeClassifier, o el n칰mero de estimadores en un RandomForestClassifier), GridSearch te ayuda a buscar la mejor combinaci칩n de valores.\n",
    "    2) Validaci칩n cruzada integrada: GridSearch utiliza cross-validation para evaluar el rendimiento de cada combinaci칩n de hiperpar치metros, asegur치ndose de que est치s maximizando el rendimiento sin sobreajustar. \n",
    "    3) Antes del entrenamiento final: Una vez que encuentras los mejores hiperpar치metros con GridSearch, puedes usarlos para entrenar el modelo final con el conjunto completo de entrenamiento.\n",
    "\n",
    "- Cu치ndo no es necesario:\n",
    "    1) Pocos hiperpar치metros importantes: Si el modelo es simple y los hiperpar치metros por defecto ya ofrecen buenos resultados, puede que no sea necesario.\n",
    "    2) Exploraci칩n inicial: Si est치s comparando muchos modelos diferentes (por ejemplo, RandomForest, AdaBoost, GradientBoosting), puede ser m치s pr치ctico ajustar hiperpar치metros b치sicos y comparar los modelos antes de usar GridSearch.\n",
    "    3) Limitaciones de tiempo o recursos: GridSearch puede ser computacionalmente costoso. Si est치s trabajando con un dataset grande o modelos complejos, tal vez quieras probar un enfoque m치s r치pido como RandomizedSearchCV.\n",
    "- Momento adecuado: Antes del modelo final. \n",
    "    - GridSearch se realiza despu칠s de hacer el preprocesamiento de los datos y seleccionar el modelo base. \n",
    "    - Usas GridSearch para ajustar los hiperpar치metros en tus datos de entrenamiento.\n",
    "    - Nunca con el test set: Los datos de prueba deben reservarse 칰nicamente para la evaluaci칩n final, despu칠s de que todos los hiperpar치metros est칠n ajustados.\n",
    "- Ventajas de GridSearch: \n",
    "    - Garantiza que todas las combinaciones de hiperpar치metros son probadas, lo que aumenta la probabilidad de encontrar la mejor configuraci칩n posible.\n",
    "    - Es f치cil de implementar usando bibliotecas como scikit-learn.\n",
    "- Limitaciones\n",
    "    - Costo computacional alto: Para modelos complejos con muchos hiperpar치metros, GridSearch puede ser muy costoso porque eval칰a todas las combinaciones posibles.\n",
    "- Alternativas m치s eficientes: Si el espacio de b칰squeda es grande, m칠todos como RandomizedSearchCV o t칠cnicas bayesianas (como Optuna) pueden ser m치s adecuados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance:\n",
    "En este caso el ejemplo es de RandomForestClassifier\n",
    "Veamos el feature importance: En cada split de los 치rboles se calcula el IG (Information Gained) teniendo en cuenta la entrop칤a antes y despu칠s del split. Se realiza una ponderaci칩n del IG en cada spllit, teniendo en cuenta la feature del split y con ello sklearn consigue el feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
