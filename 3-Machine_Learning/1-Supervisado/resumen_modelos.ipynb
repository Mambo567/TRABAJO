{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal simple y polinómica\n",
    "#### Regresión lineal simple:\n",
    "- Definición: Modela la relación lineal entre una variable independiente 𝑋 y una dependiente 𝑌.\n",
    "- Uso: Predecir valores continuos, como precio de una casa basado en tamaño.\n",
    "- Problema: Regresión.\n",
    "\n",
    "#### Regresión polinómica:\n",
    "- Definición: Extensión de la regresión lineal, pero modela relaciones no lineales elevando 𝑋 a potencias (grados polinomiales).\n",
    "- Uso: Predecir relaciones curvas, como la trayectoria de un objeto lanzado.\n",
    "- Problema: Regresión.\n",
    "\n",
    "### Regresión logística\n",
    "- Definición: Aunque se llama \"regresión\", es un modelo de clasificación que calcula probabilidades para asignar etiquetas binarias (0/1).\n",
    "- Uso: Clasificación binaria, como determinar si un correo es spam o no.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "### DecisionTreeClassifier y DecisionTreeRegressor\n",
    "#### DecisionTreeClassifier:\n",
    "- Definición: Divide datos en ramas basándose en valores de características, creando una estructura tipo árbol para clasificar.\n",
    "- Uso: Clasificación multiclase o binaria, como predecir si un cliente comprará un producto.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### DecisionTreeRegressor:\n",
    "- Definición: Igual que el anterior, pero predice valores continuos en lugar de etiquetas.\n",
    "- Uso: Estimar ingresos anuales según educación y experiencia.\n",
    "- Problema: Regresión.\n",
    "\n",
    "### RandomForestClassifier y RandomForestRegressor\n",
    "#### RandomForestClassifier\n",
    "- Definición: Ensamble de muchos árboles de decisión entrenados en subconjuntos aleatorios de los datos y características. La predicción es por votación mayoritaria.\n",
    "- Uso: Clasificación robusta con datos con ruido, como diagnóstico médico.\n",
    "- Problema: Clasificación.\n",
    "- **¿Qué hiperparámetros debería tocar en el RandomForest?**\n",
    "    1. `n_estimators`: número de árboles que participarán en las votaciones. Cuantos más mejor. NO producen overfitting. Cuanto más complejo es el dataset, mejor vendrá que haya muchos árboles. Más de 200 suele ser redundante.\n",
    "    2. `max_depth`: profundida de los árboles. Cuanto más profundos, más complejo es el modelo, pero menos generaliza. De  nuevo, cuanto más complejo es el problema, mayor profundidad necesitaremos. No más de 20/30 es lo normal.\n",
    "    3. `max_features`: features a tener en cuenta en los splits del árbol. Cuanto más bajo, mejor generalizará y menos overfitting. Numero menor a la cantidad de features del dataset, sino dará error.\n",
    "    4. `min_samples_split`: mínima cantidad de muestras en un nodo antes de ser spliteado. 2 por defecto. Números bajos suelen dar buenos resultados (<50). Cuanto más alto, mejor generaliza, pero más baja la precisión.\n",
    "    5. `min_samples_leaf`: mínima cantidad de puntos permitidos en un `leaf node`, es decir, un nodo que no va a volver a ser spliteado. Valores bajos funcionan bien (<50).\n",
    "\n",
    "#### RandomForestRegressor\n",
    "- Funciona igual pero predice valores continuos.\n",
    "\n",
    "### VotingClassifier y VotingRegressor\n",
    "#### VotingClassifier\n",
    "- Definición: Combina predicciones de diferentes modelos (pueden ser variados, como SVM, árboles, etc.), eligiendo la clase por votación (mayoría o promedio).\n",
    "- Uso: Meta-modelo para mejorar la robustez.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### VotingRegressor\n",
    "- Definición: Un meta-modelo que combina predicciones de varios modelos base regresores. Las predicciones finales son una media ponderada (o no ponderada) de las salidas de los modelos base.\n",
    "- Uso: cuando se quieren combinar múltiples modelos regresores para obtener una predicción robusta. Por ejemplo:\n",
    "- Predicción de precios de vivienda utilizando un ensamble de un modelo lineal, un Random Forest y un Gradient Boosting.\n",
    "- Problema: Regresión.\n",
    "\n",
    "### BaggingClassifier y BaggingRegressor\n",
    "#### BaggingClassifier\n",
    "- Sistema de clasificación por votación de algoritmos. En este caso siempre es el mismo tipo de algoritmo, habitualmente árboles de decisión.\n",
    "- Definición: Técnica de ensamble que entrena múltiples modelos base (por ejemplo, árboles) en subconjuntos aleatorios de los datos con reemplazo (bootstrap) y combina sus resultados.\n",
    "- Uso: Reducir la varianza y mejorar la generalización.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### BaggingRegressor\n",
    "- Definición: Técnica de ensamble que entrena múltiples versiones de un modelo base regresor en subconjuntos aleatorios (con reemplazo) de los datos de entrenamiento y promedia sus predicciones.\n",
    "- Uso: para reducir la varianza de modelos inestables como los árboles de decisión. Por ejemplo:\n",
    "- Predicción de temperaturas diarias basándose en datos históricos.\n",
    "- Problema: Regresión.\n",
    "\n",
    "### AdaBoostClassifier y AdaBoostRegressor\n",
    "#### AdaBoostClassifier\n",
    "- Definición: Ensamble de boosting que da más peso a las instancias mal clasificadas en iteraciones sucesivas, ajustando modelos base (como árboles).\n",
    "- Uso: Clasificación en datos desequilibrados o complejos.\n",
    "- Problema: Clasificación.\n",
    "- **¿Qué hiperparámetros debería tocar en el AdaBoostClassifier?**\n",
    "    1. `n_estimators`: número de árboles que participarán en la corrección secuencial del error del modelo. Si corregimos el error a la perfección el algoritmo termina de entrenar. Cuantos más estimadores, mejor corregiremos el error pero mayor probabilidad de caer en overfitting. Valores superiores a 100 suelen sobreajustar el modelo aunque dependerá de la complejidad y volumen de los datos.\n",
    "    2. `learning_rate`: no suele tener valores superiores a 1. Cuanto más alto, más aporta cada nuevo árbol, más preciso, pero caemos en overfitting. **Importante**: un learning rate bajo y alto número de estimadores no necesariamente tiene por qué aumentar la precisión y si va a inducir en altos costes computacionales.\n",
    "    3. `algorithm`: 'SAME' o 'SAME.R'. 'SAME.R' utiliza la probabilidad para actualizar los modelos aditivos, mientras que 'SAME' usa los valores de clasificación. Similar a soft vs hard voting. 'SAMME.R' converge antes que 'SAMME'\n",
    "    4. `base_estimator`: se suele dejar por defecto, aunque podría encajar un SVM o una RegresiónLogística\n",
    "    5. `max_depth`: **OJO**, no es un hiperparámetro del AdaBoostClassifier, sino del DecisionTreeClassifier. Habrá que probar varios árboles con diferentes `max_depth` y después ponerlos como `base_estimator` en el AdaBoost. Cuanto mayor es este hiperparámetro, más preciso, pero también más overfitting.\n",
    "\n",
    "#### AdaBoostRegressor\n",
    "Definición: Igual que AdaBoostClassifier, pero para predicción continua.\n",
    "Uso: Estimar valores como temperaturas futuras.\n",
    "Problema: Regresión.\n",
    "\n",
    "### ExtraTreesClassifier y ExtraTreesRegressor\n",
    "#### ExtraTreesClassifier\n",
    "- Definición: Similar a Random Forest, pero introduce más aleatoriedad al elegir los puntos de división en los árboles, lo que reduce la varianza pero puede aumentar el sesgo.\n",
    "- Uso: Clasificación en datos con muchas características redundantes.\n",
    "- Problema: Clasificación.\n",
    "- Nota clave: Es útil cuando el dataset es grande y hay correlaciones significativas entre características. Su ventaja sobre Random Forest es que es más rápido, ya que no busca las divisiones óptimas.\n",
    "\n",
    "#### ExtraTreesRegressor\n",
    "- Definición: Modelo similar al RandomForestRegressor, pero con una diferencia clave: en el RFR el modelo busca divisiones óptimas (splits) en los nodos de cada árbol, en ExtraTrees las divisiones se eligen de forma completamente aleatoria dentro de un rango de valores de las features seleccionadas. Esto incrementa la aleatoriedad y suele hacer al modelo más rápido y menos propenso al sobreajuste.\n",
    "- Características principales:\n",
    "    - Aleatoriedad extrema: Los splits en los nodos son completamente aleatorios, no el resultado de optimización como en Random Forest.\n",
    "    - Rapidez: Debido a la falta de optimización en cada nodo, entrena más rápido que un Random Forest.\n",
    "    - Menor sobreajuste: La aleatoriedad adicional actúa como una forma de regularización, haciendo que generalice mejor en algunos casos.\n",
    "- Cuándo usarlo: Cuando necesitas un modelo de regresión basado en árboles rápido y robusto. \n",
    "- En datasets donde hay muchas features redundantes o ruido, ya que la aleatoriedad puede evitar sobreajuste.\n",
    "- Problema: Solo se utiliza en regresión.\n",
    "\n",
    "### GradientBoostingClassifier y GradientBoostingRegressor\n",
    "- El GradientBoosting funciona sólo con árboles, por eso no es posible cambiar el estimador. \n",
    "- Directamente los hiperparámetros a configurar en en GradientBoosting son los del DecissionTree.\n",
    "- **¿Qué hiperparámetros debería tocar en el GradientBoosting?**\n",
    "    1. `n_estimators`: número de árboles que participarán en la corrección secuencial del error del modelo. Si corregimos el error a la perfección el algoritmo termina de entrenar. Cuantos más estimadores, mejor corregiremos el error pero mayor probabilidad de caer en overfitting. Valores superiores a 100 suelen sobreajustar el modelo aunque dependerá de la complejidad y volumen de los datos.\n",
    "    2. `learning_rate`: no suele tener valores superiores a 1. Cuanto más alto, más aporta cada nuevo árbol, más preciso, pero caemos en overfitting. **Importante**: un learning rate bajo y alto número de estimadores no necesariamente tiene por qué aumentar la precisión y si va a inducir en altos costes computacionales.\n",
    "    3. `max_depth`: Cuanto mayor es este hyperparámetro, más preciso, pero también más overfitting.\n",
    "    - Se puede iterar sobre todos los hiperparámetros recorridos en el RandomForest\n",
    "#### GradientBoostingClassifier\n",
    "- Definición: Igual que el regressor, pero para clasificación.\n",
    "- Uso: Diagnósticos médicos multiclase.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### GradientBoostingRegressor\n",
    "- Definición: Técnica de boosting que ajusta modelos secuenciales para corregir errores residuales, optimizando una métrica de pérdida específica.\n",
    "- Uso: Predecir valores como tasas de interés.\n",
    "- Problema: Regresión.\n",
    "- Explicación clave: Aunque solo usa árboles de decisión como estimadores base, permite configurar hiperparámetros como profundidad máxima o número de nodos para personalizar los árboles.\n",
    "\n",
    "### CatBoostClassifier y CatBoostRegressor\n",
    "#### CatBoostClassifier:\n",
    "- Definición: Ensamble avanzado de boosting optimizado para datos categóricos, sin necesidad de convertirlos manualmente a variables dummies.\n",
    "- Uso: Clasificación con muchas características categóricas, como datos de encuestas.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### CatBoostRegressor:\n",
    "- Definición: Igual que el anterior, pero para regresión.\n",
    "- Uso: Predecir ventas basadas en categorías como región o producto.\n",
    "- Problema: Regresión.\n",
    "\n",
    "### XGBClassifier y XGBRegressor\n",
    "- **¿Qué hiperparámetros debería tocar en el XGB?**\n",
    "    1. `n_estimators`: igual que para el GradientBoosting.\n",
    "    2. `booster`: tipo de modelo que correrá en cada iteración. Arboles o regresiones. `gbtree` or `gblinear`. Los árboles suelen ir bien.\n",
    "    3. `learning_rate`: o también llamado `eta`. Como el learning rate del GradientBoosting.\n",
    "    4. `max_depth`: nada nuevo\n",
    "    - Si quieres afinar más todavía el XGBoost consulta [esta completa guía](https://www.analyticsvidhya.com/blog/2016/03 complete-guide-parameter-tuning-xgboost-with-codes-python/).\n",
    "#### XGBClassifier:\n",
    "- Definición: Versión para clasificación de XGBoost.\n",
    "- Uso: Problemas de clasificación binaria o multiclase.\n",
    "- Problema: Clasificación.\n",
    "\n",
    "#### XGBRegressor:\n",
    "- Definición: Implementación eficiente y rápida de Gradient Boosting diseñada por XGBoost para regresión.\n",
    "- Uso: Predicciones como gasto energético.\n",
    "- Problema: Regresión.\n",
    "\n",
    "## Modelos adicionales importantes\n",
    "\n",
    "#### Support Vector Machines (SVM):\n",
    "- Definición: Encuentra un hiperplano óptimo para clasificar datos. Puede usarse para regresión (SVR) y clasificación (SVC).\n",
    "- Problema: Ambas.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN):\n",
    "- Definición: Clasifica datos basándose en las clases más comunes entre los vecinos más cercanos.\n",
    "- Problema: Clasificación, pero también regresión.\n",
    "\n",
    "#### Naive Bayes:\n",
    "- Definición: Modelo probabilístico basado en la aplicación del teorema de Bayes.\n",
    "- Problema: Clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunos insights valiosos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cross-validation con todo el dataset vs. división previa en train/test\n",
    "\n",
    "En un flujo de trabajo ideal de Machine Learning:\n",
    "\n",
    "1) Primero divides los datos en train y test para simular un entorno real de evaluación del modelo. El conjunto test se mantiene separado hasta el final del proceso, para garantizar que las métricas no estén sesgadas por decisiones previas.\n",
    "\n",
    "2) En el conjunto de entrenamiento (train), aplicas:\n",
    "\n",
    "3) Cross-validation para entrenar y evaluar iterativamente los modelos.\n",
    "\n",
    "4) Feature engineering y ajustes de hiperparámetros (si es necesario).\n",
    "\n",
    "En el caso del ejercicio que describes, hacer la cross-validation con todo el dataset (sin dividir en train/test) puede ser útil en fases exploratorias cuando:\n",
    "- No necesitas evaluar el modelo de forma estricta en un conjunto independiente.\n",
    "- Quieres entender cómo se comportan diferentes modelos en tus datos.\n",
    "\n",
    "Sin embargo, en un proyecto real, esto sería una mala práctica, porque el modelo puede sobreajustarse a los datos al no tener un conjunto de validación separado.\n",
    "\n",
    "### 2. Ensamble y elección del mejor modelo\n",
    "\n",
    "El ensamble de modelos no consiste en elegir uno mejor, sino en combinar varios modelos para obtener una predicción más robusta y precisa. Aquí hay dos puntos clave:\n",
    "\n",
    "Ensamblar modelos (como en bagging, boosting o stacking): Se usan múltiples modelos en conjunto, y sus predicciones se combinan para obtener una predicción final (por votación o promediación, por ejemplo).\n",
    "\n",
    "Si no estás ensamblando, sino probando diferentes algoritmos, entonces es normal evaluar varios modelos y elegir el que mejor rendimiento tenga.\n",
    "\n",
    "En este caso, el ejercicio te guía para comparar varios algoritmos (Bagging, Random Forest, AdaBoost, Gradient Boosting y XGBoost) con cross-validation en todo el dataset, pero en un proyecto real lo harías solo con el conjunto de entrenamiento.\n",
    "\n",
    "### 3. Flujo de trabajo ideal de ML\n",
    "\n",
    "Un flujo típico para proyectos de ML sería:\n",
    "\n",
    "1) División inicial:\n",
    "- Divide los datos en train (80%) y test (20%).\n",
    "2) Feature engineering:\n",
    "- Realiza preprocesamiento, normalización, imputación, etc., solo en train. El profe dice que se deberia hacer cross_val aqui tambien, pero que generalmente no se hace. \n",
    "3) Cross-validation:\n",
    "- Utiliza cross-validation solo en el conjunto de train para entrenar y comparar modelos.\n",
    "- Evalúa diferentes algoritmos, ajusta hiperparámetros, y selecciona el modelo o ensamble que mejor generalice.\n",
    "- Se ajustan los hiperparametros con GridSearch (ver despues) para elegir el mejor (o top3) modelo. \n",
    "- El que mejor me de, sera mi modelo. \n",
    "4) Evaluación final:\n",
    "- Una vez elegido el modelo, lo entrenas con todo el conjunto de train.\n",
    "- Evalúas su rendimiento en el conjunto de test, que no se tocó antes.\n",
    "5) Validación adicional (opcional):\n",
    "- Usa un conjunto de datos externo o validación cruzada avanzada si es posible.\n",
    "\n",
    "\n",
    "Respuesta a tu última pregunta:\n",
    "\n",
    "El objetivo de los ensamblados no es elegir un modelo único, sino usar varios modelos combinados para lograr un mejor rendimiento global. Pero en este ejercicio en particular, también te están pidiendo que compares diferentes técnicas de ensamble (bagging, boosting, etc.).\n",
    "\n",
    "Si quieres hacer este ejercicio correctamente en un proyecto real, sería mejor realizar el train-test split al inicio, trabajar con train para todo lo demás (ensamblados y comparaciones), y evaluar el mejor modelo elegido en el conjunto test al final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "\n",
    "- Técnica utilizada para encontrar la mejor combinación de hiperparámetros para un modelo de machine learning. **Trabaja en conjunto con cross-validation** para evaluar el rendimiento de cada combinación de hiperparámetros en los datos de entrenamiento, seleccionando la que maximiza una métrica de evaluación definida (por ejemplo, accuracy, F1-score, RMSE, etc.).\n",
    "\n",
    "- ¿Cómo funciona GridSearch? \n",
    "    - Definir los hiperparámetros a ajustar: Por ejemplo, si estás trabajando con un RandomForestClassifier, podrías definir un rango para los hiperparámetros n_estimators, max_depth, y min_samples_split.\n",
    "    - Crear una malla de combinaciones posibles: GridSearch probará todas las combinaciones de los valores especificados para los hiperparámetros.\n",
    "    - Realizar cross-validation para cada combinación: Usa el conjunto de datos de entrenamiento, dividiéndolo en varios folds, y evalúa el rendimiento del modelo en cada fold.\n",
    "    - Seleccionar la mejor combinación: Una vez evaluadas todas las combinaciones, GridSearch devuelve los hiperparámetros que obtuvieron el mejor rendimiento promedio en los folds.\n",
    "\n",
    "- ¿Cuándo se usa GridSearch? No siempre es necesario. Solo deberías usar GridSearch si el modelo tiene múltiples hiperparámetros que afectan significativamente su rendimiento, y no tienes una idea clara de cuáles son los mejores valores.\n",
    "    1) Optimización de hiperparámetros: Si el modelo que estás entrenando tiene hiperparámetros que impactan significativamente su rendimiento (por ejemplo, la profundidad de un árbol en un DecisionTreeClassifier, o el número de estimadores en un RandomForestClassifier), GridSearch te ayuda a buscar la mejor combinación de valores.\n",
    "    2) Validación cruzada integrada: GridSearch utiliza cross-validation para evaluar el rendimiento de cada combinación de hiperparámetros, asegurándose de que estás maximizando el rendimiento sin sobreajustar. \n",
    "    3) Antes del entrenamiento final: Una vez que encuentras los mejores hiperparámetros con GridSearch, puedes usarlos para entrenar el modelo final con el conjunto completo de entrenamiento.\n",
    "\n",
    "- Cuándo no es necesario:\n",
    "    1) Pocos hiperparámetros importantes: Si el modelo es simple y los hiperparámetros por defecto ya ofrecen buenos resultados, puede que no sea necesario.\n",
    "    2) Exploración inicial: Si estás comparando muchos modelos diferentes (por ejemplo, RandomForest, AdaBoost, GradientBoosting), puede ser más práctico ajustar hiperparámetros básicos y comparar los modelos antes de usar GridSearch.\n",
    "    3) Limitaciones de tiempo o recursos: GridSearch puede ser computacionalmente costoso. Si estás trabajando con un dataset grande o modelos complejos, tal vez quieras probar un enfoque más rápido como RandomizedSearchCV.\n",
    "- Momento adecuado: Antes del modelo final. \n",
    "    - GridSearch se realiza después de hacer el preprocesamiento de los datos y seleccionar el modelo base. \n",
    "    - Usas GridSearch para ajustar los hiperparámetros en tus datos de entrenamiento.\n",
    "    - Nunca con el test set: Los datos de prueba deben reservarse únicamente para la evaluación final, después de que todos los hiperparámetros estén ajustados.\n",
    "- Ventajas de GridSearch: \n",
    "    - Garantiza que todas las combinaciones de hiperparámetros son probadas, lo que aumenta la probabilidad de encontrar la mejor configuración posible.\n",
    "    - Es fácil de implementar usando bibliotecas como scikit-learn.\n",
    "- Limitaciones\n",
    "    - Costo computacional alto: Para modelos complejos con muchos hiperparámetros, GridSearch puede ser muy costoso porque evalúa todas las combinaciones posibles.\n",
    "- Alternativas más eficientes: Si el espacio de búsqueda es grande, métodos como RandomizedSearchCV o técnicas bayesianas (como Optuna) pueden ser más adecuados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance:\n",
    "En este caso el ejemplo es de RandomForestClassifier\n",
    "Veamos el feature importance: En cada split de los árboles se calcula el IG (Information Gained) teniendo en cuenta la entropía antes y después del split. Se realiza una ponderación del IG en cada spllit, teniendo en cuenta la feature del split y con ello sklearn consigue el feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
